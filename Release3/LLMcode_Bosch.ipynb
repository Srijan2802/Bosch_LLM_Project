{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "vVSHYhLo1WSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel(\"/content/Bosch_Dataset.xlsx\")\n",
        "df.head()"
      ],
      "metadata": {
        "id": "tYxr30651XHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfnew = df.drop(columns=[\"Review_Section\", \"Error_Type\"])"
      ],
      "metadata": {
        "id": "90jbKSHy1ZI-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dfnew.head()"
      ],
      "metadata": {
        "id": "jw1X_OSA1bRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jrJVeVhb1KnE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from dotenv import load_dotenv\n",
        "from openai import AzureOpenAI\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "class LLMErrorDetector:\n",
        "    \"\"\"\n",
        "    Detects error types in product reviews using an LLM (Azure OpenAI),\n",
        "    categorizing them as 'Semantic Misalignment', 'Specialized Error', or 'Clean'.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, openai_api_key: str = None, api_base: str = None, api_version: str = None, deployment: str = None):\n",
        "        \"\"\"\n",
        "        Initialize with explicit parameters or environment variables.\n",
        "        \"\"\"\n",
        "        load_dotenv()  # Load environment variables from .env file\n",
        "\n",
        "        # Set configuration with explicit parameters or environment variables\n",
        "        self.api_key = openai_api_key or os.environ.get(\"AZURE_OPENAI_API_KEY\", \"\")\n",
        "        self.api_version = api_version or os.environ.get(\"AZURE_OPENAI_API_VERSION\", \"2024-08-01-preview\")\n",
        "        self.api_base = api_base or os.environ.get(\"AZURE_OPENAI_ENDPOINT\", \"\")\n",
        "        self.deployment = deployment or os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\", \"gpt-4o\")\n",
        "\n",
        "        # Initialize client only if we have required credentials\n",
        "        self.client = None\n",
        "        self.api_available = False\n",
        "\n",
        "        if self.api_key and self.api_base:\n",
        "            try:\n",
        "                self.client = AzureOpenAI(\n",
        "                    api_key=self.api_key,\n",
        "                    api_version=self.api_version,\n",
        "                    azure_endpoint=self.api_base\n",
        "                )\n",
        "                # Test the connection\n",
        "                self._test_connection()\n",
        "            except Exception as e:\n",
        "                print(f\"Failed to initialize Azure OpenAI client: {e}\")\n",
        "                print(\"Will continue with local fallback classification method.\")\n",
        "\n",
        "    def _test_connection(self):\n",
        "        \"\"\"Test the API connection with a minimal request\"\"\"\n",
        "        try:\n",
        "            # Simple test to check if the API works\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.deployment,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"Hello\"},\n",
        "                    {\"role\": \"user\", \"content\": \"Test connection\"}\n",
        "                ],\n",
        "                max_tokens=5\n",
        "            )\n",
        "            self.api_available = True\n",
        "            print(\"Azure OpenAI API connection successful!\")\n",
        "        except Exception as e:\n",
        "            self.api_available = False\n",
        "            print(f\"Azure OpenAI API connection test failed: {e}\")\n",
        "            print(\"API Authentication Error: Please check your Azure OpenAI API credentials.\")\n",
        "            print(\"1. Verify your API key is correct.\")\n",
        "            print(\"2. Confirm your endpoint URL is correct.\")\n",
        "            print(\"3. Make sure your API version is valid.\")\n",
        "            print(\"4. Check that your deployment name exists.\")\n",
        "\n",
        "    def _clean_json_response(self, raw_output: str) -> str:\n",
        "        \"\"\"\n",
        "        Cleans the raw output from the API to extract just the JSON part.\n",
        "        Handles cases where JSON is wrapped in markdown code blocks.\n",
        "        \"\"\"\n",
        "        # Remove markdown code block syntax if present\n",
        "        code_block_pattern = r\"```(?:json)?\\s*([\\s\\S]*?)```\"\n",
        "        match = re.search(code_block_pattern, raw_output)\n",
        "\n",
        "        if match:\n",
        "            # Extract the content inside the code block\n",
        "            return match.group(1).strip()\n",
        "\n",
        "        return raw_output.strip()\n",
        "\n",
        "    def analyze_review(self, product_name: str, review_text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Analyzes a review using Azure OpenAI or falls back to a simple rule-based method\n",
        "        if the API is not available.\n",
        "        \"\"\"\n",
        "        if self.api_available and self.client:\n",
        "            return self._analyze_with_api(product_name, review_text)\n",
        "        else:\n",
        "            return self._fallback_analysis(product_name, review_text)\n",
        "\n",
        "    def _analyze_with_api(self, product_name: str, review_text: str) -> dict:\n",
        "        \"\"\"Use Azure OpenAI API to analyze the review\"\"\"\n",
        "\n",
        "        user_prompt = f\"\"\"\n",
        "You are a Bosch power tool expert. Analyze the following review and classify it into one of these categories:\n",
        "\n",
        "1. Clean: The review contains no errors in understanding of the product's functionality or terminology.\n",
        "\n",
        "2. Semantic Misalignment: The review contains misunderstandings of the tool's function or usage\n",
        "(e.g., using a drill to cut wood), misuse of product-related terms (e.g., calling a cordless drill \"battery-free\"),\n",
        "or wrong assumptions about what a tool can do.\n",
        "\n",
        "3. Specialized Error: The review contains highly technical errors related to specific tool features, performance metrics,\n",
        "or specialized usage contexts that would only be known to professionals or experts in the field.\n",
        "\n",
        "Tool: '{product_name}'\n",
        "Review: '{review_text}'\n",
        "\n",
        "Your response must be valid JSON in this format:\n",
        "{{\n",
        "  \"Error_Type\": \"Clean\" or \"Semantic Misalignment\" or \"Specialized Error\",\n",
        "  \"Review_Section\": \"Brief explanation of why the review is classified this way\",\n",
        "  \"Corrective_Measure\": \"How the review can be corrected if there is an error, or N/A if clean\"\n",
        "}}\n",
        "\n",
        "DO NOT wrap the JSON in markdown code blocks or any other formatting - just return the raw JSON object.\n",
        "\"\"\"\n",
        "\n",
        "        try:\n",
        "            response = self.client.chat.completions.create(\n",
        "                model=self.deployment,\n",
        "                messages=[\n",
        "                    {\n",
        "                        \"role\": \"system\",\n",
        "                        \"content\": \"You are a domain expert analyzing product reviews for different types of errors. Always return only valid JSON without markdown formatting.\"\n",
        "                    },\n",
        "                    {\n",
        "                        \"role\": \"user\",\n",
        "                        \"content\": user_prompt\n",
        "                    }\n",
        "                ],\n",
        "                temperature=0.0\n",
        "            )\n",
        "\n",
        "            raw_output = response.choices[0].message.content.strip()\n",
        "\n",
        "            # Clean the response to extract just the JSON part\n",
        "            cleaned_json_str = self._clean_json_response(raw_output)\n",
        "\n",
        "            try:\n",
        "                output_json = json.loads(cleaned_json_str)\n",
        "                return output_json\n",
        "            except json.JSONDecodeError as e:\n",
        "                print(f\"Failed to parse JSON: {cleaned_json_str}\")\n",
        "                print(f\"Error: {e}\")\n",
        "\n",
        "                # Try a more aggressive approach to extract valid JSON\n",
        "                try:\n",
        "                    # Find anything that looks like a JSON object\n",
        "                    json_pattern = r\"\\{[\\s\\S]*\\}\"\n",
        "                    match = re.search(json_pattern, cleaned_json_str)\n",
        "                    if match:\n",
        "                        potential_json = match.group(0)\n",
        "                        return json.loads(potential_json)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "                # If all parsing attempts fail, extract the basic information manually\n",
        "                error_type_match = re.search(r'\"Error_Type\":\\s*\"([^\"]+)\"', cleaned_json_str)\n",
        "                review_section_match = re.search(r'\"Review_Section\":\\s*\"([^\"]+)\"', cleaned_json_str)\n",
        "                corrective_match = re.search(r'\"Corrective_Measure\":\\s*\"([^\"]+)\"', cleaned_json_str)\n",
        "\n",
        "                return {\n",
        "                    \"Error_Type\": error_type_match.group(1) if error_type_match else \"Unknown\",\n",
        "                    \"Review_Section\": review_section_match.group(1) if review_section_match else \"Failed to parse\",\n",
        "                    \"Corrective_Measure\": corrective_match.group(1) if corrective_match else \"No suggestion\"\n",
        "                }\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"OpenAI API call failed: {e}\")\n",
        "            return {\n",
        "                \"Error_Type\": \"Unknown\",\n",
        "                \"Review_Section\": f\"API Error: {str(e)}\",\n",
        "                \"Corrective_Measure\": \"No suggestion due to API error\"\n",
        "            }\n",
        "\n",
        "    def _fallback_analysis(self, product_name: str, review_text: str) -> dict:\n",
        "        \"\"\"\n",
        "        Simplified rule-based fallback method when API is unavailable.\n",
        "        This is just a very basic implementation - you may want to enhance it.\n",
        "        \"\"\"\n",
        "        review_lower = review_text.lower()\n",
        "\n",
        "        # Very simple keyword-based classification\n",
        "        semantic_keywords = [\n",
        "            \"battery-free\", \"cordless\", \"wireless\", \"cut wood with drill\",\n",
        "            \"hammer with screwdriver\", \"screwdriver to chisel\", \"without power\",\n",
        "            \"router\", \"sds-max\", \"precision drilling\"\n",
        "        ]\n",
        "\n",
        "        specialized_keywords = [\n",
        "            \"torque rating\", \"rpm\", \"amperage\", \"voltage incorrect\",\n",
        "            \"technical specification\", \"wrong specs\"\n",
        "        ]\n",
        "\n",
        "        # Check for semantic misalignment\n",
        "        for keyword in semantic_keywords:\n",
        "            if keyword.lower() in review_lower:\n",
        "                return {\n",
        "                    \"Error_Type\": \"Semantic Misalignment\",\n",
        "                    \"Review_Section\": f\"Contains potential semantic error with term: {keyword}\",\n",
        "                    \"Corrective_Measure\": \"Please verify the correct terminology and tool usage\"\n",
        "                }\n",
        "\n",
        "        # Check for specialized errors\n",
        "        for keyword in specialized_keywords:\n",
        "            if keyword.lower() in review_lower:\n",
        "                return {\n",
        "                    \"Error_Type\": \"Specialized Error\",\n",
        "                    \"Review_Section\": f\"Contains potential specialized error: {keyword}\",\n",
        "                    \"Corrective_Measure\": \"Please review technical specifications and correct\"\n",
        "                }\n",
        "\n",
        "        # Default to Clean if no keywords match\n",
        "        return {\n",
        "            \"Error_Type\": \"Clean\",\n",
        "            \"Review_Section\": \"No obvious errors detected (fallback analysis)\",\n",
        "            \"Corrective_Measure\": \"N/A\"\n",
        "        }\n",
        "\n",
        "    def process_reviews(self, reviews_file: str) -> pd.DataFrame:\n",
        "        \"\"\"\n",
        "        Reads an Excel file with columns including Product_ID, Product_Name, Review, Error_Type (ground truth),\n",
        "        analyzes each review, adds prediction columns, and calculates accuracy metrics.\n",
        "        \"\"\"\n",
        "        try:\n",
        "            df = pd.read_excel(reviews_file)\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading Excel file: {e}\")\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # Check if the ground truth column exists\n",
        "        has_ground_truth = \"Error_Type\" in df.columns\n",
        "\n",
        "        if has_ground_truth:\n",
        "            # Rename the ground truth column to avoid overwriting\n",
        "            df.rename(columns={\"Error_Type\": \"True_Error_Type\"}, inplace=True)\n",
        "\n",
        "        # Add or reset prediction columns\n",
        "        df[\"Error_Type\"] = None\n",
        "        df[\"Review_Section\"] = None\n",
        "        df[\"Corrective_Measure\"] = None\n",
        "\n",
        "        # Process each review\n",
        "        for idx, row in df.iterrows():\n",
        "            product_name = row.get(\"Product_Name\", \"\")\n",
        "            review_text = row.get(\"Review\", \"\")\n",
        "\n",
        "            # Skip if essential data is missing\n",
        "            if not product_name or not review_text:\n",
        "                df.at[idx, \"Error_Type\"] = \"Unknown\"\n",
        "                df.at[idx, \"Review_Section\"] = \"Missing product name or review text\"\n",
        "                df.at[idx, \"Corrective_Measure\"] = \"N/A\"\n",
        "                continue\n",
        "\n",
        "            # Analyze the review\n",
        "            parsed_output = self.analyze_review(product_name, review_text)\n",
        "\n",
        "            # Update the dataframe with the analysis results\n",
        "            df.at[idx, \"Error_Type\"] = parsed_output.get(\"Error_Type\", \"Unknown\")\n",
        "            df.at[idx, \"Review_Section\"] = parsed_output.get(\"Review_Section\", \"\")\n",
        "            df.at[idx, \"Corrective_Measure\"] = parsed_output.get(\"Corrective_Measure\", \"\")\n",
        "\n",
        "            # Show progress\n",
        "            if (idx + 1) % 10 == 0 or idx == len(df) - 1:\n",
        "                print(f\"Processed {idx + 1}/{len(df)} reviews\")\n",
        "\n",
        "        # Calculate accuracy metrics if ground truth is available\n",
        "        if has_ground_truth:\n",
        "            self.calculate_accuracy(df)\n",
        "\n",
        "        # Save results\n",
        "        output_file = reviews_file.replace(\".xlsx\", \"_analyzed.xlsx\")\n",
        "        try:\n",
        "            df.to_excel(output_file, index=False)\n",
        "            print(f\"Results saved to: {output_file}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Error saving results to Excel: {e}\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    def calculate_accuracy(self, df: pd.DataFrame) -> None:\n",
        "        \"\"\"\n",
        "        Calculate and print accuracy metrics based on ground truth labels.\n",
        "        \"\"\"\n",
        "        print(\"\\n===== ACCURACY METRICS =====\")\n",
        "\n",
        "        # Filter out rows with missing values\n",
        "        valid_rows = df.dropna(subset=[\"True_Error_Type\", \"Error_Type\"])\n",
        "\n",
        "        if len(valid_rows) == 0:\n",
        "            print(\"No valid rows with both ground truth and predictions for accuracy calculation.\")\n",
        "            return\n",
        "\n",
        "        # Overall accuracy\n",
        "        accuracy = accuracy_score(valid_rows[\"True_Error_Type\"], valid_rows[\"Error_Type\"])\n",
        "        print(f\"Overall Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "        # Class-specific metrics\n",
        "        print(\"\\nClassification Report:\")\n",
        "        report = classification_report(\n",
        "            valid_rows[\"True_Error_Type\"],\n",
        "            valid_rows[\"Error_Type\"],\n",
        "            zero_division=0\n",
        "        )\n",
        "        print(report)\n",
        "\n",
        "        # Confusion matrix\n",
        "        print(\"\\nConfusion Matrix:\")\n",
        "        labels = [\"Clean\", \"Semantic Misalignment\", \"Specialized Error\"]\n",
        "\n",
        "        # Filter to only include labels that exist in the data\n",
        "        existing_labels = list(set(list(valid_rows[\"True_Error_Type\"].unique()) +\n",
        "                                  list(valid_rows[\"Error_Type\"].unique())))\n",
        "        existing_labels = [label for label in labels if label in existing_labels]\n",
        "\n",
        "        cm = confusion_matrix(\n",
        "            valid_rows[\"True_Error_Type\"],\n",
        "            valid_rows[\"Error_Type\"],\n",
        "            labels=existing_labels\n",
        "        )\n",
        "\n",
        "        # Create a DataFrame for better visualization\n",
        "        cm_df = pd.DataFrame(\n",
        "            cm,\n",
        "            index=[f\"True: {label}\" for label in existing_labels],\n",
        "            columns=[f\"Pred: {label}\" for label in existing_labels]\n",
        "        )\n",
        "        print(cm_df)\n",
        "\n",
        "        # Calculate per-class counts and accuracies\n",
        "        print(\"\\nPer-Class Performance:\")\n",
        "        classes = [\"Clean\", \"Semantic Misalignment\", \"Specialized Error\"]\n",
        "        for cls in classes:\n",
        "            true_count = sum(valid_rows[\"True_Error_Type\"] == cls)\n",
        "            correct_count = sum((valid_rows[\"True_Error_Type\"] == cls) & (valid_rows[\"Error_Type\"] == cls))\n",
        "\n",
        "            if true_count > 0:\n",
        "                class_accuracy = correct_count / true_count\n",
        "                print(f\"{cls}: {correct_count}/{true_count} correct ({class_accuracy:.2f})\")\n",
        "            else:\n",
        "                print(f\"{cls}: No ground truth instances\")\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Get user input for API credentials\n",
        "    print(\"Azure OpenAI Credentials (leave blank to use environment variables):\")\n",
        "    api_key = input(\"API Key (press Enter to use environment variable): \").strip() or None\n",
        "    api_base = input(\"API Endpoint (press Enter to use environment variable): \").strip() or None\n",
        "    api_version = input(\"API Version (press Enter to use default '2024-08-01-preview'): \").strip() or None\n",
        "    deployment = input(\"Deployment Name (press Enter to use default 'gpt-4o'): \").strip() or None\n",
        "\n",
        "    # Initialize the detector\n",
        "    detector = LLMErrorDetector(\n",
        "        openai_api_key=api_key,\n",
        "        api_base=api_base,\n",
        "        api_version=api_version,\n",
        "        deployment=deployment\n",
        "    )\n",
        "\n",
        "    # Get the input file path\n",
        "    input_file = input(\"Enter the path to your Excel file (e.g., sample_reviews.xlsx): \").strip()\n",
        "\n",
        "    if not os.path.exists(input_file):\n",
        "        print(f\"File not found: {input_file}\")\n",
        "        return\n",
        "\n",
        "    # Process the reviews\n",
        "    df_result = detector.process_reviews(input_file)\n",
        "\n",
        "    if not df_result.empty:\n",
        "        print(\"\\nFinal Results Sample:\")\n",
        "        columns_to_show = [\"Product_ID\", \"Product_Name\", \"Review\"]\n",
        "        if \"True_Error_Type\" in df_result.columns:\n",
        "            columns_to_show.append(\"True_Error_Type\")\n",
        "        columns_to_show.extend([\"Error_Type\", \"Review_Section\", \"Corrective_Measure\"])\n",
        "\n",
        "        print(df_result[columns_to_show].head())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}