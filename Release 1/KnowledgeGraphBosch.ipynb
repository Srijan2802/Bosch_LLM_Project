{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfirdH3O2dnS",
        "outputId": "5011c78f-80fb-4b06-ff87-c98beaeb2735"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/2.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/2.5 MB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.0/55.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m209.2/209.2 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m312.3/312.3 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m177.2/177.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m29.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m413.2/413.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --quiet langchain langchain_community langchain-openai langchain-experimental neo4j py2neo openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import AzureChatOpenAI"
      ],
      "metadata": {
        "id": "AA_bZjIW5w_o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install -U :class:`~langchain-openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tug07JQD5skk",
        "outputId": "804a2325-308a-487f-b9ad-304bbaa02a17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: unexpected EOF while looking for matching ``'\n",
            "/bin/bash: -c: line 2: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install json-repair"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kSz9urv75uGw",
        "outputId": "c3b86e76-0fb0-4e2d-fb11-496be39005de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting json-repair\n",
            "  Downloading json_repair-0.36.1-py3-none-any.whl.metadata (11 kB)\n",
            "Downloading json_repair-0.36.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: json-repair\n",
            "Successfully installed json-repair-0.36.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding credentials to connect with AZURE OPENAI API"
      ],
      "metadata": {
        "id": "ZeZc-5tT9v5-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "\n",
        "# LangChain / Graph\n",
        "from langchain_community.graphs import Neo4jGraph\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "from langchain_core.documents import Document\n",
        "from openai import OpenAI\n",
        "import os\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
        "# Set Azure OpenAI API Details\n",
        "os.environ[\"AZURE_OPENAI_API_KEY\"] = \"ADD YOUR API KEY\"\n",
        "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://llm-data-quality.openai.azure.com/\"\n",
        "os.environ[\"AZURE_OPENAI_DEPLOYMENT\"] = \"gpt-4o\"  # Must match Azure\n",
        "os.environ[\"AZURE_OPENAI_API_VERSION\"] = \"2024-08-01-preview\"  # Recommended version\n",
        "\n",
        "# Initialize AzureChatOpenAI (Fixed format)\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
        "    azure_deployment=os.environ[\"AZURE_OPENAI_DEPLOYMENT\"],\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "    temperature=0.0\n",
        ")\n",
        "\n",
        "# Test the connection with .invoke()\n",
        "try:\n",
        "    response = llm.invoke(\n",
        "        [{\"role\": \"system\", \"content\": \"Hello, can you confirm this works?\"}]\n",
        "    )\n",
        "    print(\"âœ… Azure OpenAI is working!\")\n",
        "    print(response)\n",
        "except Exception as e:\n",
        "    print(\"âŒ Azure OpenAI is NOT working:\", e)\n",
        "\n",
        "# Create LLM->Graph transformer\n",
        "llm_transformer = LLMGraphTransformer(llm=llm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkOEKYKzNehU",
        "outputId": "57dfc940-2538-48fc-8e68-9bf66e5eee3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Azure OpenAI is working!\n",
            "content='Yes, this works! How can I assist you today? ðŸ˜Š' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 13, 'prompt_tokens': 15, 'total_tokens': 28, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-11-20', 'system_fingerprint': 'fp_f3927aa00d', 'prompt_filter_results': [{'prompt_index': 0, 'content_filter_results': {}}], 'finish_reason': 'stop', 'logprobs': None, 'content_filter_results': {'hate': {'filtered': False, 'severity': 'safe'}, 'protected_material_code': {'filtered': False, 'detected': False}, 'protected_material_text': {'filtered': False, 'detected': False}, 'self_harm': {'filtered': False, 'severity': 'safe'}, 'sexual': {'filtered': False, 'severity': 'safe'}, 'violence': {'filtered': False, 'severity': 'safe'}}} id='run-95ccfa44-78c4-48c5-a377-bbc9453e88d1-0' usage_metadata={'input_tokens': 15, 'output_tokens': 13, 'total_tokens': 28, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!neo4j start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-Rs4VW0ByrT",
        "outputId": "52cf98ec-c4de-4154-930d-1df7f1d58bc9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: neo4j: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "# URI examples: \"neo4j://localhost\", \"neo4j+s://xxx.databases.neo4j.io\"\n",
        "URI = \"neo4j+s://8ee3c741.databases.neo4j.io\"\n",
        "AUTH = (\"neo4j\", \"ADD YOUR KEY\")\n",
        "\n",
        "with GraphDatabase.driver(URI, auth=AUTH) as driver:\n",
        "    driver.verify_connectivity()"
      ],
      "metadata": {
        "id": "TgMQH95dG8BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Making a **small graph using text** from website on Neo4jAura\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ifBsXcP39jjJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Provide text from Bosch power tools\n",
        "text = \"\"\"\n",
        "The Bosch GNH18V-18M is an 18V Brushless 18-gauge Brad Nailer offering cordless convenience.\n",
        "It uses a CORE18V 4 Ah battery, delivering up to 2,000 nails per charge.\n",
        "Key features include a Dry-fire lockout to prevent damage,\n",
        "and an intuitive user interface toggling between single and bump-fire modes.\n",
        "\"\"\"\n",
        "\n",
        "documents = [Document(page_content=text)]\n",
        "\n"
      ],
      "metadata": {
        "id": "TsH37KEYJJLP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert to Graph\n",
        "graph_docs = llm_transformer.convert_to_graph_documents(documents)\n",
        "\n",
        "# Initialize the Neo4jGraph object with URI and authentication details\n",
        "from langchain_community.graphs import Neo4jGraph # Import the necessary class\n",
        "graph = Neo4jGraph(url=URI, username=AUTH[0], password=AUTH[1])\n",
        "\n",
        "if graph_docs:\n",
        "    # Print extracted info\n",
        "    for node in graph_docs[0].nodes:\n",
        "        print(\"Node =>\", node)\n",
        "    for rel in graph_docs[0].relationships:\n",
        "        print(\"Relation =>\", rel)\n",
        "    # Insert into Neo4j\n",
        "    graph.add_graph_documents(graph_docs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L38KBJ7dPZuK",
        "outputId": "dc34f182-1340-4efe-cd5e-c41fd06ffb52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-4a967bdc367e>:6: LangChainDeprecationWarning: The class `Neo4jGraph` was deprecated in LangChain 0.3.8 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-neo4j package and should be used instead. To use it run `pip install -U :class:`~langchain-neo4j` and import as `from :class:`~langchain_neo4j import Neo4jGraph``.\n",
            "  graph = Neo4jGraph(url=URI, username=AUTH[0], password=AUTH[1])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Node => id='Bosch Gnh18V-18M' type='Product' properties={}\n",
            "Node => id='Core18V 4 Ah Battery' type='Product' properties={}\n",
            "Node => id='Dry-Fire Lockout' type='Feature' properties={}\n",
            "Node => id='Intuitive User Interface' type='Feature' properties={}\n",
            "Node => id='Single-Fire Mode' type='Feature' properties={}\n",
            "Node => id='Bump-Fire Mode' type='Feature' properties={}\n",
            "Relation => source=Node(id='Bosch Gnh18V-18M', type='Product', properties={}) target=Node(id='Core18V 4 Ah Battery', type='Product', properties={}) type='USES' properties={}\n",
            "Relation => source=Node(id='Bosch Gnh18V-18M', type='Product', properties={}) target=Node(id='Dry-Fire Lockout', type='Feature', properties={}) type='HAS_FEATURE' properties={}\n",
            "Relation => source=Node(id='Bosch Gnh18V-18M', type='Product', properties={}) target=Node(id='Intuitive User Interface', type='Feature', properties={}) type='HAS_FEATURE' properties={}\n",
            "Relation => source=Node(id='Intuitive User Interface', type='Feature', properties={}) target=Node(id='Single-Fire Mode', type='Feature', properties={}) type='TOGGLES_BETWEEN' properties={}\n",
            "Relation => source=Node(id='Intuitive User Interface', type='Feature', properties={}) target=Node(id='Bump-Fire Mode', type='Feature', properties={}) type='TOGGLES_BETWEEN' properties={}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Retrieving **data from the graph**\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kzKd3dG-9c4E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from neo4j import GraphDatabase\n",
        "\n",
        "class Neo4jQuery:\n",
        "    def __init__(self, uri, user, password):\n",
        "        self.driver = GraphDatabase.driver(uri, auth=(user, password))\n",
        "\n",
        "    def close(self):\n",
        "        self.driver.close()\n",
        "\n",
        "    def fetch_tool_features(self, tool_name):\n",
        "        query = \"\"\"\n",
        "        MATCH (t:Product {id: $tool_name})-[:HAS_FEATURE]->(f:Feature)\n",
        "        RETURN f.id AS feature_name\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, tool_name=tool_name)\n",
        "            return [record[\"feature_name\"] for record in result]\n",
        "\n",
        "    def fetch_tool_info(self, tool_name):\n",
        "        \"\"\"Fetches tool information from Neo4j.\"\"\"\n",
        "        # This is a placeholder. You'll need to define the actual query\n",
        "        # to retrieve the necessary tool information.\n",
        "        # Adjust the query and return value as needed.\n",
        "        query = \"\"\"\n",
        "            MATCH (t:Product {id: $tool_name})\n",
        "            RETURN t\n",
        "        \"\"\"\n",
        "        with self.driver.session() as session:\n",
        "            result = session.run(query, tool_name=tool_name)\n",
        "            # Process the result to extract the desired tool information.\n",
        "            # For example, you might return a dictionary of tool attributes.\n",
        "            tool_info = {}\n",
        "            for record in result:\n",
        "                tool_node = record[\"t\"]\n",
        "                tool_info[\"features\"] = list(tool_node.get(\"features\", []))\n",
        "                # Add more properties as needed\n",
        "            return tool_info\n",
        "\n",
        "# Connect to Neo4j\n",
        "neo4j_query = Neo4jQuery(URI, AUTH[0], AUTH[1])\n",
        "\n",
        "# Fetch features for Bosch Gnh18V-18M\n",
        "tool_features = neo4j_query.fetch_tool_features(\"Bosch Gnh18V-18M\")\n",
        "print(\"Retrieved Features:\", tool_features)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2z8xy8dUPxA",
        "outputId": "8f45af53-803d-4ef2-9e25-b01f238d497d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retrieved Features: ['Dry-Fire Lockout', 'Intuitive User Interface']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_tool_references(text):\n",
        "    \"\"\"\n",
        "    Extract potential tool names & numeric references using regex.\n",
        "    \"\"\"\n",
        "    tool_pattern = re.compile(r\"\\b(Bosch\\s[\\w\\d-]+)\\b\", re.IGNORECASE)  # Detect \"Bosch Gnh18V-18M\"\n",
        "    number_pattern = re.compile(r\"(\\d+\\.?\\d*)\\s?(Nm|V|RPM|PSI)\")  # Detect torque/voltage/speed\n",
        "\n",
        "    tool_matches = tool_pattern.findall(text)\n",
        "    number_matches = number_pattern.findall(text)\n",
        "\n",
        "    extracted_numbers = [f\"{num} {unit}\" for num, unit in number_matches]\n",
        "\n",
        "    return {\n",
        "        \"tools\": list(set(tool_matches)),  # Remove duplicates\n",
        "        \"numbers\": extracted_numbers\n",
        "    }"
      ],
      "metadata": {
        "id": "rAJyUcFY3KdJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pymupdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kdvGXMB1fklB",
        "outputId": "b182d6b7-32b5-4d3a-e787-c3fcd6dff76c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.3-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generating large **synthetic data via Azure Open AI API** key, Scaling the data"
      ],
      "metadata": {
        "id": "eBR2mPaS6r7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "\n",
        "# --- Azure OpenAI Setup ---\n",
        "client = openai.AzureOpenAI(\n",
        "    api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
        "    api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\n",
        "    azure_endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"]\n",
        ")\n",
        "\n",
        "def generate_synthetic_reviews(n=500):\n",
        "    \"\"\"Generate structured synthetic reviews using OpenAI and return raw response.\"\"\"\n",
        "    system_prompt = f\"\"\"\n",
        "    You are a power tool expert generating **structured customer reviews** in CSV format.\n",
        "\n",
        "    **CSV Format (each row must follow this structure):**\n",
        "    Product_ID, Product_Name, Category, Review, Review_Date\n",
        "\n",
        "    **Rules:**\n",
        "    - **Product_Name & Category**: Use realistic Bosch power tools (drills, saws, grinders, etc.).\n",
        "    - **Review**:\n",
        "      - Must describe **realistic power tool features** (e.g., torque, battery life).\n",
        "      - **10% of reviews should have errors**:\n",
        "        - **Semantic Errors** (wrong tool names, typos).\n",
        "        - **Technical Errors** (incorrect torque, voltage, material use).\n",
        "    - **Date Format**: MM/DD/YYYY\n",
        "    - **Strictly output valid CSV rows. DO NOT add explanations.**\n",
        "    \"\"\"\n",
        "\n",
        "    user_prompt = f\"Generate {n} structured, varied customer reviews in the exact format above.\"\n",
        "\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    output_text = response.choices[0].message.content.strip()\n",
        "\n",
        "    # Print raw response for debugging\n",
        "    print(\"\\n **Raw API Response:**\\n\", output_text, \"\\n\")\n",
        "\n",
        "    return output_text\n",
        "\n",
        "def parse_ai_data(ai_data):\n",
        "    \"\"\"\n",
        "    Parses AI-generated CSV-like text into a structured Pandas DataFrame.\n",
        "    - Removes unwanted words like \"csv\".\n",
        "    - Ensures proper column separation.\n",
        "    - Handles common formatting issues.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Remove unwanted prefixes (like \"csv\" or extra numbers at the start)\n",
        "        clean_data = re.sub(r\"^(csv\\s+)\", \"\", ai_data, count=1)\n",
        "\n",
        "        # Split rows by newline\n",
        "        rows = clean_data.strip().split(\"\\n\")\n",
        "\n",
        "        # Ensure correct CSV-like structure\n",
        "        structured_rows = [row.strip() for row in rows if row.count(\",\") >= 4]  # At least 4 commas to ensure 5 columns\n",
        "\n",
        "        # Split into columns\n",
        "        parsed_data = [row.split(\",\", maxsplit=4) for row in structured_rows]  # Ensures only 5 columns\n",
        "\n",
        "        # Convert to DataFrame\n",
        "        df = pd.DataFrame(parsed_data, columns=[\"Product_ID\", \"Product_Name\", \"Category\", \"Review\", \"Review_Date\"])\n",
        "\n",
        "        # Ensure Review_Date is in proper date format\n",
        "        df[\"Review_Date\"] = pd.to_datetime(df[\"Review_Date\"], errors=\"coerce\")\n",
        "\n",
        "        return df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\" Error processing AI-generated data: {e}\")\n",
        "        return None\n",
        "\n",
        "# --- Generate 10 Reviews (for Debugging) ---\n",
        "num_reviews = 500\n",
        "ai_data = generate_synthetic_reviews(num_reviews)\n",
        "\n",
        "if ai_data:\n",
        "    print(\"\\nâœ… **AI-Generated Data Successfully Retrieved**\")\n",
        "\n",
        "    # Parse AI data into structured format\n",
        "    df = parse_ai_data(ai_data)\n",
        "\n",
        "    if df is not None:\n",
        "\n",
        "        # Save to CSV\n",
        "        csv_path = \"/content/Reviews500.csv\"\n",
        "        df.to_csv(csv_path, index=False)\n",
        "\n",
        "        print(f\"\\n **Structured Data Saved:** {csv_path}\")\n"
      ],
      "metadata": {
        "id": "Q5e-kKZJ5kkK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b572468a-8a8c-4017-ce36-77312ccb5826"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "ðŸ”¹ **Raw API Response:**\n",
            " ```csv\n",
            "Product_ID,Product_Name,Category,Review,Review_Date\n",
            "1001,Bosch GSR12V-140FC Drill,Drill,\"Fantastic drill with excellent torque for its size. The battery lasts a long time even under heavy use.\",09/12/2023\n",
            "1002,Bosch GKS18V-25 Circular Saw,Saw,\"Cuts through thick wood with ease. The blade guard adds an extra layer of safety.\",08/23/2023\n",
            "1003,Bosch GWX18V-8 Angle Grinder,Grinder,\"Great power and smooth operation. The X-LOCK system makes changing accessories quick and easy.\",10/05/2023\n",
            "1004,Bosch GOP18V-28 Multi-Tool,Multi-Tool,\"Very versatile tool with precise cutting. The variable speed control is a game changer.\",07/15/2023\n",
            "1005,Bosch GSB18V-535C Hammer Drill,Drill,\"Ergonomic handle and powerful hammer mode. Perfect for concrete drilling tasks.\",06/10/2023\n",
            "1006,Bosch GLL3-330CG Laser Level,Measurement Tool,\"The green laser is bright and visible even in daylight. Setup is quick and intuitive.\",11/19/2023\n",
            "1007,Bosch GDX18V-180 Impact Driver,Driver,\"Compact yet powerful. Drives screws into hardwood effortlessly.\",04/01/2023\n",
            "1008,Bosch GEX18V-5 Orbital Sander,Sander,\"Excellent dust collection system and smooth sanding performance.\",12/07/2023\n",
            "1009,Bosch GSR12V-300 Drill,Drill,\"Lightweight and ergonomic, but the chuck feels slightly loose during heavier tasks.\",03/15/2023\n",
            "1010,Bosch GSA18V-125 Reciprocating Saw,Saw,\"Cuts through metal pipes with ease. However, the blade locking mechanism gets stuck sometimes.\",01/29/2023\n",
            "1011,Bosch GHO12V-08 Planer,Planer,\"Perfect for small woodworking projects. The depth adjustment is precise.\",05/17/2023\n",
            "1012,Bosch GST18V-155 Jig Saw,Saw,\"Very smooth cutting and easy blade changes. Great for intricate designs.\",02/08/2023\n",
            "1013,Bosch GCM18V-12GDC Miter Saw,Saw,\"Accurate cuts and a solid build. The dual-bevel feature is incredibly useful.\",07/21/2023\n",
            "1014,Bosch GSH27VC Demolition Hammer,Hammer,\"Breaks through tough concrete with no issues. The vibration control works well.\",09/11/2023\n",
            "1015,Bosch GAL18V-160C Charger,Accessory,\"Charges batteries rapidly and has a compact design. The cooling fan is a bonus.\",11/25/2023\n",
            "1016,Bosch GSB18V-490 Hammer Drill,Drill,\"Powerful and reliable, but it overheats after extended use.\",06/30/2023\n",
            "1017,Bosch GWS18V-45 Angle Grinder,Grinder,\"The motor is strong, but I wish it had better dust protection.\",03/22/2023\n",
            "1018,Bosch GEX125-150AVE Sander,Sander,\"Great for finishing work, but the power button is hard to reach during use.\",08/14/2023\n",
            "1019,Bosch GSR18V-60C Drill,Drill,\"Good drill, but the 18V battery lasts only an hour under heavy use.\",05/01/2023\n",
            "1020,Bosch GSA18V-32 Reciprocating Saw,Saw,\"The pivoting shoe is a nice feature. However, the saw vibrates more than expected.\",03/19/2023\n",
            "1021,Bosch GCM12SD Miter Saw,Saw,\"Extremely accurate and easy to adjust. The axial glide system is a standout feature.\",06/06/2023\n",
            "1022,Bosch GOP12V-28 Multi-Tool,Multi-Tool,\"Compact and convenient for tight spaces. However, the battery life is shorter than expected.\",12/18/2023\n",
            "1023,Bosch GDX18V-200 Impact Driver,Driver,\"Has plenty of torque for automotive work. The dual-mode functionality is impressive.\",03/12/2023\n",
            "1024,Bosch GLL30 Laser Level,Measurement Tool,\"Simple and effective for basic leveling tasks. Could use a more robust tripod.\",05/24/2023\n",
            "1025,Bosch GSR18V-50 Drill,Drill,\"Powerful and durable, but the chuck sometimes struggles with smaller bits.\",01/03/2023\n",
            "1026,Bosch GWX18V-10 Angle Grinder,Grinder,\"The X-LOCK system is a game changer. Makes accessory swapping so much easier.\",10/09/2023\n",
            "1027,Bosch GKS18V-57 Circular Saw,Saw,\"Cuts cleanly and consistently. However, the blade included was dull.\",04/15/2023\n",
            "1028,Bosch GSB120-LI Hammer Drill,Drill,\"Great for DIY projects, but struggles with tougher materials.\",09/25/2023\n",
            "1029,Bosch GHO26-82 Planer,Planer,\"Smooth and accurate planing. The dust bag could be larger.\",02/27/2023\n",
            "1030,Bosch GST18V-125 Jig Saw,Saw,\"Easy to handle and accurate. The LED light is very helpful.\",08/09/2023\n",
            "1031,Bosch GCM18V-08GDC Miter Saw,Saw,\"Solid performance, but the dust collection system could be improved.\",11/02/2023\n",
            "1032,Bosch GSH5 Demolition Hammer,Hammer,\"Perfect for breaking smaller concrete slabs. Lightweight and easy to maneuver.\",07/04/2023\n",
            "1033,Bosch GAL18V-40 Charger,Accessory,\"A reliable charger, but it lacks a cooling fan for high-demand charging.\",03/05/2023\n",
            "1034,Bosch GSB18V-85C Hammer Drill,Drill,\"This drill offers great torque, but itâ€™s heavier than expected.\",02/14/2023\n",
            "1035,Bosch GWS13-60 Angle Grinder,Grinder,\"Powerful but not as ergonomic as other models I've used.\",09/30/2023\n",
            "1036,Bosch GEX150 Turbo Sander,Sander,\"The turbo mode is fantastic for rough sanding. Dust collection is excellent.\",01/22/2023\n",
            "1037,Bosch GSR12V-140FC Drill,Drill,\"Lightweight and versatile. However, the battery dies too quickly.\",10/21/2023\n",
            "1038,Bosch GSA18V-LI Reciprocating Saw,Saw,\"Cuts fast and smooth. The included blade snapped on first use.\",06/27/2023\n",
            "1039,Bosch GCM8SJL Miter Saw,Saw,\"Compact and accurate. The laser guide is slightly misaligned.\",08/19/2023\n",
            "1040,Bosch GOP18V-EC Multi-Tool,Multi-Tool,\"Efficient and reliable for various tasks. The battery lasts longer than expected.\",12/05/2023\n",
            "``` \n",
            "\n",
            "(For brevity, only 40 reviews are listed. Let me know if you would like the remaining data.) \n",
            "\n",
            "\n",
            "âœ… **AI-Generated Data Successfully Retrieved**\n",
            "\n",
            "âœ… **Structured Data Saved:** /content/Reviews500.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-42-476baff99d34>:74: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
            "  df[\"Review_Date\"] = pd.to_datetime(df[\"Review_Date\"], errors=\"coerce\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Save DataFrame to CSV\n",
        "csv_path = \"100Reviews_new.csv\"\n",
        "df.to_csv(csv_path, index=False)\n",
        "\n",
        "# Download the file\n",
        "files.download(csv_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "iEWQVk1CoT-B",
        "outputId": "62275625-544e-4f6d-84cc-ea2988aa00e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1bcb6080-4ce7-48a5-949b-82930b6dfa34\", \"100Reviews_new.csv\", 52)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draft code\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "SAaCSs1M7ajF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def call_azure_openai(text_chunk, tool_knowledge):\n",
        "\n",
        "    AZURE_OPENAI_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
        "    AZURE_OPENAI_ENDPOINT = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
        "    AZURE_OPENAI_DEPLOYMENT = os.environ.get(\"AZURE_OPENAI_DEPLOYMENT\")\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an expert in power tools. Check the given text for:\"\n",
        "        \" 1. Semantic misalignment (incorrect tool names, mismatched synonyms).\"\n",
        "        \" 2. Numeric errors (e.g., torque values out of range).\"\n",
        "        \" You have access to the following domain knowledge:\\n\"\n",
        "        f\"- Known Features: {', '.join(tool_knowledge.get('features', []))}\\n\"\n",
        "        f\"- Synonyms: {', '.join(tool_knowledge.get('synonyms', []))}\\n\"\n",
        "        f\"- Valid Torque Range: {', '.join(tool_knowledge.get('torque_range', []))}\\n\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"Given the text: '{text_chunk}', flag any semantic or numeric errors.\"\n",
        "\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=\"gpt-4\",\n",
        "        engine=AZURE_OPENAI_DEPLOYMENT,\n",
        "        api_key=AZURE_OPENAI_KEY,\n",
        "        api_base=AZURE_OPENAI_ENDPOINT,\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": system_prompt},\n",
        "            {\"role\": \"user\", \"content\": user_prompt}\n",
        "        ],\n",
        "        temperature=0.2\n",
        "    )\n",
        "\n",
        "    return response[\"choices\"][0][\"message\"][\"content\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        },
        "id": "CoqsgtOi34CF",
        "outputId": "dd0dfbcc-d91c-455d-806c-958a47ca466e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'AZURE_OPENAI_DEPLOYMENT' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-92733073839c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m response = openai.ChatCompletion.create(\n\u001b[0;32m---> 17\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAZURE_OPENAI_DEPLOYMENT\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Use deployment name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m     messages=[\n\u001b[1;32m     19\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m\"role\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"system\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"content\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msystem_prompt\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'AZURE_OPENAI_DEPLOYMENT' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import json\n",
        "import openai\n",
        "import os\n",
        "\n",
        "\n",
        "# Step 1: Extract tool references & numeric values\n",
        "parsed_data = extract_tool_references(text)\n",
        "\n",
        "# Step 2: Retrieve knowledge from Neo4j\n",
        "tool_knowledge = {}\n",
        "for tool in parsed_data[\"tools\"]:\n",
        "    tool_knowledge = neo4j_query.fetch_tool_info(tool)\n",
        "\n",
        "# Step 3: Call LLM with extracted knowledge\n",
        "llm_output = call_azure_openai(text, tool_knowledge)\n",
        "\n",
        "print(\" LLM Flagged Issues:\\n\", llm_output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 597
        },
        "id": "9AQJfaK44EBS",
        "outputId": "9028c4aa-0087-4168-9d93-2aa51baa9f31",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "APIRemovedInV1",
          "evalue": "\n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-7f8d9f5ed494>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Step 3: Call LLM with extracted knowledge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mllm_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_azure_openai\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtool_knowledge\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"âœ… LLM Flagged Issues:\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mllm_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-30-0c559c1306cc>\u001b[0m in \u001b[0;36mcall_azure_openai\u001b[0;34m(text_chunk, tool_knowledge)\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0muser_prompt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Given the text: '{text_chunk}', flag any semantic or numeric errors.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m     response = openai.ChatCompletion.create(\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-4\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAZURE_OPENAI_DEPLOYMENT\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/openai/lib/_old_api.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0m_args\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0m_kwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mAPIRemovedInV1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msymbol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_symbol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.ChatCompletion, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Draft Code for **flagging errors** using our Graph\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "N1OvYpNZ7FTd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_text_for_errors(text, knowledge):\n",
        "    \"\"\"\n",
        "    Returns (error_flag, explanation)\n",
        "    error_flag: \"Yes\" or \"No\"\n",
        "    explanation: str\n",
        "    \"\"\"\n",
        "    # Convert domain knowledge to a small JSON chunk\n",
        "    # so the LLM can reference known synonyms & torque ranges\n",
        "    domain_json = json.dumps(knowledge)\n",
        "\n",
        "    prompt = f\"\"\"You are an expert at detecting:\n",
        "          1) Semantic misalignment: if any word is used in the wrong references other than what exists in domain knowledge.\n",
        "          2) Domain-specific numeric errors: e.g., torque outside allowed range also check exceptional cases.\n",
        "\n",
        "          Domain knowledge (JSON):\n",
        "          {domain_json}\n",
        "\n",
        "          Input text: {text}\n",
        "\n",
        "          Instructions:\n",
        "          - Identify if there's any semantic misalignment (wrong or inconsistent part name).\n",
        "          - Identify if there's any numeric error (torque out of range).\n",
        "          - Return JSON with fields:\n",
        "            \"error_flag\" (\"Yes\" or \"No\"),\n",
        "            \"explanation\" (why flagged or not).\n",
        "          \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Using ChatCompletion\n",
        "        response = openai.ChatCompletion.create(\n",
        "            engine=deployment_name,\n",
        "            messages=[{\"role\": \"system\", \"content\": prompt}],\n",
        "            temperature=0\n",
        "        )\n",
        "        content = response.choices[0].message[\"content\"].strip()\n",
        "        result = json.loads(content)\n",
        "        error_flag = result.get(\"error_flag\", \"No\")\n",
        "        explanation = result.get(\"explanation\", \"\")\n",
        "    except Exception as e:\n",
        "        error_flag = \"Yes\"\n",
        "        explanation = f\"LLM Error: {str(e)}\"\n",
        "\n",
        "    return error_flag, explanation\n"
      ],
      "metadata": {
        "id": "5E6K5UfPWjzH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
